{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b1cbfc5",
      "metadata": {
        "id": "0b1cbfc5"
      },
      "source": [
        "**sEMG CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f83b6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This file contains the necessary code to train the sEMG signals classifier, through a ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S-85GtAkPDA3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-85GtAkPDA3",
        "outputId": "63c1f691-de97-4c8f-d065-917947bab718"
      },
      "outputs": [],
      "source": [
        "# Use the following lines if you want to use Google Colab\n",
        "# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n",
        "# NOTE: terminate all other colab sessions that use GPU!\n",
        "# NOTE 2: Make sure the correct exercise folder (e.g exercise_10) is given.\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "gdrive_path='/content/gdrive/MyDrive/adl4r'\n",
        "\n",
        "# This will mount your google drive under 'MyDrive'\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# In order to access the files in this notebook we have to navigate to the correct folder\n",
        "os.chdir(gdrive_path)\n",
        "# Check manually if all files are present\n",
        "print(sorted(os.listdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "382064e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "382064e0",
        "outputId": "94f5a3dc-4f33-4152-ab5d-50bc24d9f097"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jgual\\anaconda3\\envs\\your_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version Installed: 1.13.1\n",
            "Torchvision version Installed: 0.14.1+cpu\n",
            "\n",
            "you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it might cause dependency and compatibility issues.\n",
            "you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it might cause dependency and compatibility issues.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(f\"PyTorch version Installed: {torch.__version__}\\nTorchvision version Installed: {torchvision.__version__}\\n\")\n",
        "if not torch.__version__.startswith(\"1.11\"):\n",
        "    print(\"you are using an another version of PyTorch. We expect PyTorch 1.11.0. You may continue using your version but it\"\n",
        "          \" might cause dependency and compatibility issues.\")\n",
        "if not torchvision.__version__.startswith(\"0.12\"):\n",
        "    print(\"you are using an another version of torchvision. We expect torchvision 0.12. You can continue with your version but it\"\n",
        "          \" might cause dependency and compatibility issues.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "062977c0",
      "metadata": {
        "id": "062977c0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14176\\764827552.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# default='warn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'autoreload'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "import sklearn.metrics\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "825b490d",
      "metadata": {
        "id": "825b490d"
      },
      "outputs": [],
      "source": [
        "# DATASET AND DATALOADER\n",
        "\n",
        "from sEMG_dataset import sEMGDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # Apply any necessary transformations\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Generation of the training, validation, and testing datasets\n",
        "train_dataset = sEMGDataset(\"./semg_dataset/spectrograms_concat\",mode = 'train', split = {'train': 0.8, 'val': 0.1, 'test': 0.1}, transform = transform)\n",
        "val_dataset = sEMGDataset(\"./semg_dataset/spectrograms_concat\",mode = 'val', split = {'train': 0.8, 'val': 0.1, 'test': 0.1}, transform = transform)\n",
        "test_dataset = sEMGDataset(\"./semg_dataset/spectrograms_concat\",mode = 'test', split = {'train': 0.8, 'val': 0.1, 'test': 0.1}, transform = transform)\n",
        "\n",
        "# Generation of the training, validation, and testing datasets\n",
        "train_dataloader = DataLoader(train_dataset , batch_size=10, shuffle=True, num_workers=2, drop_last=False)\n",
        "val_dataloader = DataLoader(val_dataset , batch_size=10, shuffle=True, num_workers=2, drop_last=False)\n",
        "test_dataloader = DataLoader(test_dataset , batch_size=10, shuffle=True, num_workers=2, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2PH3TUMWbwfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PH3TUMWbwfa",
        "outputId": "a3eb2575-c7a6-42d8-ba07-8ac6403b5f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training length: 270\n",
            "Validation length: 270\n",
            "Test length: 270\n",
            "Sample shape: torch.Size([6, 480, 640])\n"
          ]
        }
      ],
      "source": [
        "# Evaluation of samples contained in each dataset\n",
        "print('Training length: ' + str(len(test_dataset)))\n",
        "print('Validation length: ' + str(len(val_dataset)))\n",
        "print('Test length: ' + str(len(test_dataset)))\n",
        "print('Sample shape: ' + str(train_dataset[0][0].shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6609aa01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6609aa01",
        "outputId": "2f3ca460-9945-491a-8dbd-1de798c9c4d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jgual\\anaconda3\\envs\\your_env\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
            "c:\\Users\\jgual\\anaconda3\\envs\\your_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Classifier (ResNet18)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Model definition\n",
        "model = models.resnet18(pretrained = False)\n",
        "\n",
        "# Adjust the classification (channels in and channels out)\n",
        "num_channels = 6  # channels in\n",
        "model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "num_classes = 6 # channels out\n",
        "num_features = model.fc.in_features  # Número de características en la capa de clasificación actual\n",
        "model.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "# Loss function to be used for classification CE Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer definition: Adam SGD\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum= 0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "988149cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "988149cd",
        "outputId": "fd029c17-2951-477b-9bd8-cb04546de1f2"
      },
      "outputs": [],
      "source": [
        "# TRAINING OUR CLASSIFIER\n",
        "\n",
        "# Number of epochs to be trained\n",
        "n_epochs = 45\n",
        "\n",
        "# Set device config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Utilizar GPU si está disponible\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Initializing the list for storing the loss and accuracy\n",
        "train_loss_history = [] # loss\n",
        "train_acc_history = [] # accuracy\n",
        "val_loss_history = [] # loss validation\n",
        "val_acc_history = [] # accuracy validation\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    # TRAINING\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    \n",
        "    for imgs, labels in train_dataloader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Reset the parameter gradients  for the current  minibatch iteration \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(imgs)             # Perform a forward pass on the network with inputs\n",
        "        loss = criterion(y_pred, labels) # calculate the loss with the network predictions and ground Truth\n",
        "        loss.backward()             # Perform a backward pass to calculate the gradients\n",
        "        optimizer.step()            # Optimize the network parameters with calculated gradients\n",
        "\n",
        "        \n",
        "        # Accumulate the loss and calculate the accuracy of predictions\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(y_pred, 1) #convert output probabilities of each class to a singular class prediction\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "\n",
        "    #print and store statistics\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_accuracy = correct / len(train_dataset)\n",
        "    train_loss_history.append(epoch_loss)\n",
        "    train_acc_history.append(epoch_accuracy)\n",
        "\n",
        "    print(\"[Epoch %d] --> Train loss: %.3f Train accuracy: %.2f %%\" % (epoch+1, epoch_loss, epoch_accuracy*100))\n",
        "\n",
        "\n",
        "    # VALIDATION\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "   \n",
        "    for imgs, labels in val_dataloader:\n",
        "        with torch.no_grad():\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            y_pred = model(imgs)             # Perform a forward pass on the network with inputs\n",
        "            loss = criterion(y_pred, labels) # calculate the loss with the network predictions and ground Truth\n",
        "            \n",
        "            # Accumulate the loss and calculate the accuracy of predictions\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(y_pred, 1) #convert output probabilities of each class to a singular class prediction\n",
        "            correct += torch.sum(preds == labels).item()\n",
        "\n",
        "    #print and store statistics\n",
        "    epoch_loss = running_loss / len(val_dataset)\n",
        "    epoch_accuracy = correct / len(val_dataset)\n",
        "    val_loss_history.append(epoch_loss)\n",
        "    val_acc_history.append(epoch_accuracy)\n",
        "\n",
        "    print(\"[Epoch %d] --> Val loss: %.3f Val accuracy: %.2f %%\" % (epoch+1, epoch_loss, epoch_accuracy*100))\n",
        "    print('--------------')\n",
        "    \n",
        "\n",
        "print('FINISH.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923009a7",
      "metadata": {
        "id": "923009a7"
      },
      "outputs": [],
      "source": [
        "# PLOT TRAIN AND VALIDATION LOSS/ACCURACY\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loss\n",
        "plt.plot(range(1, n_epochs+1), train_loss_history, label='Train Loss')\n",
        "plt.plot(range(1, n_epochs+1), val_loss_history, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(range(1, n_epochs+1), train_acc_history, label='Train Accuracy')\n",
        "plt.plot(range(1, n_epochs+1), val_acc_history, label='Val Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wbO9vKmIiMJ1",
      "metadata": {
        "id": "wbO9vKmIiMJ1"
      },
      "outputs": [],
      "source": [
        "# TESTING\n",
        "model.eval()\n",
        "running_loss = 0.0\n",
        "correct = 0.0\n",
        "acc = 0.0\n",
        "recall = 0.0    \n",
        "precision = 0.0\n",
        "f1 = 0.0\n",
        "confusion = np.zeros((6, 6))\n",
        "\n",
        "\n",
        "for imgs, labels in test_dataloader:\n",
        "    with torch.no_grad():\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        y_pred = model(imgs)             # Perform a forward pass on the network with inputs\n",
        "        loss = criterion(y_pred, labels) # calculate the loss with the network predictions and ground Truth\n",
        "        \n",
        "        # Accumulate the loss and calculate the accuracy of predictions\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(y_pred, 1) #convert output probabilities of each class to a singular class prediction\n",
        "        correct += torch.sum(preds == labels).item()\n",
        "        preds = preds.data.cpu().numpy()\n",
        "        targets = labels.data.cpu().numpy()\n",
        "        recall += sklearn.metrics.recall_score(targets.flatten(), preds.flatten(),\n",
        "                                               average=\"weighted\", zero_division=0)\n",
        "        precision += sklearn.metrics.precision_score(targets.flatten(), preds.flatten(),\n",
        "                                                     average=\"weighted\", zero_division=0)\n",
        "        f1 += sklearn.metrics.f1_score(targets.flatten(), preds.flatten(),\n",
        "                                       average=\"weighted\", zero_division=0)\n",
        "        \n",
        "        for j in range(len(imgs)):\n",
        "            confusion[preds[j], targets[j]] += 1\n",
        "\n",
        "\n",
        "#print and store statistics\n",
        "epoch_loss = running_loss / len(test_dataset)\n",
        "epoch_accuracy = correct / len(test_dataset)\n",
        "\n",
        "f = open(\"test_2_45e.txt\", \"w\")\n",
        "print(confusion, file=f)\n",
        "print(\"Test accuracy: %.2f %%\" % (epoch_accuracy*100), file=f)\n",
        "print('Recall: {:.4f}'.format(recall / len(test_dataloader)), file=f)\n",
        "print('Precision: {:.4f}'.format(precision / len(test_dataloader)), file=f)\n",
        "print('f1: {:.4f}'.format(f1 / len(test_dataloader)), file=f)\n",
        "\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
